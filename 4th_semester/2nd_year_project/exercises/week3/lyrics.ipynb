{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyrics Era classification with Naive Bayes \n",
    "\n",
    "You will implement a Naive Bayes text classifier that classifies song lyrics by era.\n",
    "\n",
    "In particular, we created a dataset for you that consists of song lyrics from *heavy metal bands* spanning the last half century!\n",
    "\n",
    "<img src=\"pics/cover.jpg\">\n",
    "\n",
    "*This assignment is inspired from material by J.Eisenstein*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('data/metal-lyrics-train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe is a structured representation of your data. You can preview a dataframe using `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's inspect an example. Can you guess the era? :) [Can the machine do so?]\n",
    "df_train['Lyrics'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='blue'>Task 1</font>: Representing and inspecting the data - Bags of word (BOW), Label distribution and OOV rate\n",
    "\n",
    "Your first task is to convert the text into a bag-of-words representation.\n",
    "\n",
    "\n",
    "- **Deliverable 1.1**: implement `bag_of_words`, a counter of all words in a single document. Decide how to tokenize the data. Load the data files `data/metal-lyrics-train.csv` and `data/metal-lyrics-dev.csv` and inspect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# deliverable 1.1\n",
    "def bag_of_words(text):\n",
    "    '''\n",
    "    Count the number of word occurrences for each document in the corpus. The function also tokenizes the text.\n",
    "\n",
    "    :param text: a document, as a single string\n",
    "    :returns: a Counter for a single document\n",
    "    :rtype: Counter\n",
    "    '''\n",
    "    # your code here\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper code\n",
    "    \n",
    "def read_data(filename, label='Era', text=\"Lyrics\", preprocessor=bag_of_words):\n",
    "    '''\n",
    "    Read the data and convert with preprocessor\n",
    "    '''\n",
    "    df = pd.read_csv(filename)\n",
    "    return df[label].values, [preprocessor(string) for string in df[text].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data\n",
    "\n",
    "## your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Distribution\n",
    "\n",
    "- **Deliverable 1.2**: inspect the data. Plot the label distribution in the training and dev data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unseen words\n",
    "\n",
    "One challenge for classification is that words will appear in the test data that do not appear in the training data. Compute the number of words that appear in `metal-lyrics-dev.csv`, but not in `metal-lyrics-train.csv`. To do this, implement the following deliverables:\n",
    "\n",
    "\n",
    "- **Deliverable 1.3**: implement `aggregate_counts`, a counter of all words in a list of bags-of-words. This function  creates the vocabulary over the entire dataset (here the vocabulary are all unique *word types*).\n",
    "- **Deliverable 1.4**: implement `compute_oov`, returning a list of words that appear in one list of bags-of-words, but not another.  Then, use your implementation to calculate the out-of-vocabulary (OOV) rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deliverable 1.3\n",
    "def aggregate_counts(bags_of_words):\n",
    "    '''\n",
    "    Aggregate word counts for individual documents into a single bag of words representation\n",
    "\n",
    "    :param bags_of_words: a list of bags of words as Counters from the bag_of_words method\n",
    "    :returns: an aggregated bag of words for the whole corpus\n",
    "    :rtype: Counter\n",
    "    '''\n",
    "\n",
    "    counts = Counter()\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "\n",
    "    \n",
    "# deliverable 1.4\n",
    "def compute_oov(bow1, bow2):\n",
    "    '''\n",
    "    Return a set of words that appears in bow1, but not bow2\n",
    "\n",
    "    :param bow1: a bag of words\n",
    "    :param bow2: a bag of words\n",
    "    :returns: the set of words in bow1, but not in bow2\n",
    "    :rtype: set\n",
    "    '''\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "# helper code\n",
    "def oov_rate(bow1, bow2):\n",
    "    return len(compute_oov(bow1, bow2)) / len(bow1.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have implemented the functions, we can use them to calculate the OOV rate.\n",
    "- **Deliverable 1.5**: calculate the OOV rate on the dev data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of words in the dev set do not appear in the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power laws\n",
    "\n",
    "Word count distributions are said to follow [power law](https://en.wikipedia.org/wiki/Power_law) distributions. \n",
    "\n",
    "In practice, this means that a log-log plot of frequency against rank is nearly linear. Let's see if this holds for our data.\n",
    "\n",
    "You can see the most common items in a counter by calling `counts.most_common()`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.loglog([val for word, val in counts_tr.most_common()])\n",
    "plt.loglog([val for word, val in counts_dv.most_common()])\n",
    "plt.xlabel('rank')\n",
    "plt.ylabel('frequency')\n",
    "plt.legend(['training set','dev set']);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would this curve look like if it were not plotted in log space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "Latex Macros\n",
    "-->\n",
    "$$\n",
    "\\newcommand{\\Xs}{\\mathcal{X}}\n",
    "\\newcommand{\\Ys}{\\mathcal{Y}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\weights}{\\mathbf{w}}\n",
    "\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\aligns}{\\mathbf{a}}\n",
    "\\newcommand{\\align}{a}\n",
    "\\newcommand{\\source}{\\mathbf{s}}\n",
    "\\newcommand{\\target}{\\mathbf{t}}\n",
    "\\newcommand{\\ssource}{s}\n",
    "\\newcommand{\\starget}{t}\n",
    "\\newcommand{\\repr}{\\mathbf{f}}\n",
    "\\newcommand{\\repry}{\\mathbf{g}}\n",
    "\\newcommand{\\bar}{\\,|\\,}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\prob}{p}\n",
    "\\newcommand{\\Pulp}{\\text{Pulp}}\n",
    "\\newcommand{\\Fiction}{\\text{Fiction}}\n",
    "\\newcommand{\\PulpFiction}{\\text{Pulp Fiction}}\n",
    "\\newcommand{\\pnb}{\\prob^{\\text{NB}}}\n",
    "\\newcommand{\\vocab}{V}\n",
    "\\newcommand{\\params}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\param}{\\theta}\n",
    "\\DeclareMathOperator{\\perplexity}{PP}\n",
    "\\DeclareMathOperator{\\argmax}{argmax}\n",
    "\\DeclareMathOperator{\\argmin}{argmin}\n",
    "\\newcommand{\\train}{\\mathcal{D}}\n",
    "\\newcommand{\\counts}[2]{\\#_{#1}(#2) }\n",
    "\\newcommand{\\length}[1]{\\text{length}(#1) }\n",
    "\\newcommand{\\indi}{\\mathbb{I}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Task 2</font>: Naive Bayes\n",
    "\n",
    "You'll now implement a Naive Bayes classifier for this task.\n",
    "\n",
    "\n",
    "###  Naive Bayes Prediction\n",
    "\n",
    "Given a trained NB model (we have estimated model parameters $\\params$), we search for the $y\\in\\Ys$ with maximum *a posteriori* probability:\n",
    "\n",
    "$$\n",
    "\\argmax_{y\\in\\Ys} \\prob_\\params(y|\\x) =  \\argmax_{y\\in\\Ys} \\frac{\\prob(\\x|y) \\prob(y) }{ \\prob(\\x) } =\\\\ \\argmax_{y\\in\\Ys} \\prob(\\x|y) \\prob(y) \n",
    "$$\n",
    "\n",
    "\n",
    "where the parameters $\\params$ in NB consist of two sets:\n",
    "* $\\prob(y)$ - prior probability (or $\\bbeta$ for class priors) \n",
    "* $\\prob(\\x|y)$ - likelihood (or $\\balpha$, per-class feature probabilities)\n",
    "\n",
    "To train the model, we use Maximum Likelihood estimation: \n",
    "\n",
    "\\begin{split}\n",
    "  \\alpha_{w,y} & = \\frac{\\counts{\\train}{w,y}}{\\sum_{w'}\\counts{\\train}{w',y}}\\\\\\\\\n",
    "  \\beta_{y} & = \\frac{\\counts{\\train}{y}}{\\left| \\train \\right|}\n",
    "\\end{split}\n",
    "\n",
    "\n",
    "Write Python code to use a training set of documents to estimate the probabilities in the Naive Bayes model. Return the data structure containing the probabilities. The input parameter of this function should be a list of lyrics with labels. \n",
    "\n",
    "Hints:\n",
    "\n",
    "* use *log* probabilities to avoid numeric over/underflow.\n",
    "* we drop words that are unknown at test time completely (as mentioned in J&M, we don’t use unknown word models for naive Bayes)\n",
    "* first implement a model without any smoothing; evaluate it; then add Laplace smoothing to the likelihoods and observe how that impacts performance\n",
    "* it might help to develop your model first on toy data; for this purpose we include the worked example from Section 4.3 of the textbook (`data/tinysentiment*.csv`)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='blue'>Task 2.A </font>: Towards estimating likelihood - counting features per class\n",
    "\n",
    "Above you have implemented code to convert the text into a bag-of-words representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the estimation of the Naive Bayes likelihood parameters, we are interested in counting the number of times a word appears, given a certain class. \n",
    "\n",
    "- **Deliverable 1.4**: implement `aggregate_counts_for_label`, a counter of all words in a list of bags-of-words for a specific label only. \n",
    "\n",
    "Test it on the provided worked toy example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deliverable 1.4\n",
    "def aggregate_counts_for_label(bags_of_words, y_train, label):\n",
    "    '''\n",
    "    Aggregate word counts for individual documents given a certain label (class) into a single bag of words representation\n",
    "\n",
    "    :param bags_of_words: a list of bags of words as Counters from the bag_of_words method\n",
    "    :param label: the class we (later used to compute the likelihood term p(w|class))\n",
    "    :returns: an aggregated bag of words for the subset of the corpus specific to the given label\n",
    "    :rtype: Counter\n",
    "    '''\n",
    "\n",
    "    counts = Counter()\n",
    "    # your code here\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the toy example and inspect the aggregate counts\n",
    "## your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='blue'>Task 2.B </font>:  Implement Naive Bayes (from scratch)\n",
    "\n",
    "\n",
    "- **Deliverable 2.1**: implement `train_nb`, which estimates the parameters for the Naive Bayes model. \n",
    "\n",
    "- **Deliverable 2.2**: evaluate the estimated model parameters on the evaluation dataset. Add Laplace smoothing and observe what happens to the performance of the model. \n",
    "\n",
    "Tipps:\n",
    "\n",
    "- we provide helper code below. You are free to ignore it and code it up your own way (with dictionaries or whichever structure you feel most comfortable with)\n",
    "- for efficiency reasons, the code below creates a data structure in which all model parameters end up in a matrix, which allows for very efficient processing. In particular, the model parameter matrix will be of size `num_features x classes`, in which the first row is reserved for the prior class probabilities and all rows from 1 onwards contain the likelihoods of the feature given the class. Some useful functions are `np.array()`, `np.sum(data, axis=0)` and [`np.nan_to_num`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.nan_to_num.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpful numpy code\n",
    "a = np.array([[0, 0, 1, 0],\n",
    "              [1, 1, 2, 10],\n",
    "              [4, 0, 0, 1],\n",
    "              [1, 2, 0, 0]])\n",
    "\n",
    "b = a / a.sum(axis=0)\n",
    "b\n",
    "# Probabilities must sum to one! (or very close)\n",
    "print(\"sum to one:\", b.sum(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper code \n",
    "from abc import ABC\n",
    "\n",
    "class LinearClassifier(ABC):\n",
    "    \"\"\"\n",
    "    General class for a linear classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.trained = False\n",
    "        self.lab2idx = {} # mapping of each class label to an index\n",
    "        self.feat2idx = {} # mapping of features to indices\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Estimates the model parameters\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_scores(self, x, w):\n",
    "        \"\"\"\n",
    "        Computes the dot product between X and w (several instances at once)\n",
    "        \"\"\"\n",
    "        return np.dot(x, w)\n",
    "\n",
    "    def get_label(self, x, w):\n",
    "        \"\"\"\n",
    "        Computes the label for each data instance\n",
    "        \"\"\"\n",
    "        scores = np.dot(x, w)\n",
    "        return np.argmax(scores, axis=1).transpose()\n",
    "\n",
    "    def test(self, x, w):\n",
    "        \"\"\"\n",
    "        Finds the most likely label for each instance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise Error(\"Please train the model first\")\n",
    "        idx2lab = {i: lab for lab, i in self.lab2idx.items()} # reverse mapping\n",
    "        x_matrix = np.zeros((len(x),len(self.feat2idx)+1)) # add prior\n",
    "        for i, inst in enumerate(x):\n",
    "            # add prior\n",
    "            for j, p_c in enumerate(w[0]):\n",
    "                x_matrix[i][0] = 1\n",
    "            # likelihood\n",
    "            for f in inst:\n",
    "                if f in self.feat2idx: #otherwise ignore\n",
    "                    fIdx = self.feat2idx[f]\n",
    "                    x_matrix[i][fIdx] = inst[f]\n",
    "               \n",
    "        predicted_label_indices = self.get_label(x_matrix, w)\n",
    "        return [idx2lab[i] for i in predicted_label_indices]\n",
    "\n",
    "    def evaluate(self, gold, predicted):\n",
    "        \"\"\"\n",
    "        Estimate accuracy of the predictions\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for g,p in zip(gold,predicted):\n",
    "            if g == p:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayes(LinearClassifier):\n",
    "\n",
    "    def __init__(self):\n",
    "        LinearClassifier.__init__(self)\n",
    "        self.is_trained = False\n",
    "\n",
    "    def train(self, X, y):\n",
    "        print(\"Training a multinomial NB model\")\n",
    "        params = self.train_nb(X, y)\n",
    "        self.is_trained = True\n",
    "        return params\n",
    "    \n",
    "    ### deliverable 2.1\n",
    "    def train_nb(self, X_train, y_train):\n",
    "        # estimate the model parameters\n",
    "        \n",
    "        # this function should return the following matrix\n",
    "        # \n",
    "        #   parameters = np.zeros((vocab_size+1, num_classes))\n",
    "        #\n",
    "        #   where\n",
    "        #    - the first row [0] contains the prior (log probs) per class  parameters[0, i] = log p of c\n",
    "        #    - and the remaining rows contain the per class likelihood parameters[1:, i]\n",
    "        #\n",
    "           \n",
    "        num_classes = len(np.unique(y_train))\n",
    "        features_train = aggregate_counts(X_train)\n",
    "        vocab_size = len(features_train)\n",
    "        print(\"{} classes, {} vocab size\".format(num_classes, vocab_size))\n",
    "\n",
    "        \n",
    "        # instantiate mappers\n",
    "        self.feat2idx = {f: i+1 for i,f in enumerate(features_train)}  # keep 0 reserved for prior \n",
    "        self.lab2idx = {l: i for i,l in enumerate(np.unique(y_train))}\n",
    "\n",
    "\n",
    "        # your code here\n",
    "        \n",
    "        \n",
    "        #return parameters\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the worked toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='blue'>Task 3</font>: Evaluation and Analysis\n",
    "\n",
    "**Deliverable 2.3**: Evaluate your model on the metal lyrics dev set. Create a confusion matrix. Which classes are often confused with each other?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate - deliverable 2.2 & deliverable 2.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
