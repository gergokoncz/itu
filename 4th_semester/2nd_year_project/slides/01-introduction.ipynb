{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Welcome to 2nd year project!\n",
    "\n",
    "### Natural Language Processing and Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Never Sleeps\n",
    "\n",
    "E.g., In 2019, how many tweets were send *every minute*? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"pics/data-never-sleeps.png\" width=400>\n",
    "Src: DOMO Data never sleeps 7.0 (https://www.domo.com/learn/data-never-sleeps-7)[https://www.domo.com/learn/data-never-sleeps-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Science is OSEMN!\n",
    "* OSEMN model (Hilary Mason, 2010) \n",
    "* Pronounced 'awesome'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"pics/osemn.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Natural Language Processing (NLP)?\n",
    "\n",
    "* an **interdisciplinary** research field\n",
    "* **Goal:** enabling computers to **understand** and **generate** language, just as we humans do\n",
    "* Deep understanding of **broad** language\n",
    "    * not just string processing or keyword matching\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Course practicalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Who are we?\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "    <td><img src=\"pics/bapl.jpg\" width=200px></td>\n",
    "    <td> <img src=\"pics/rob.jpg\" width=200px> </td>\n",
    "    <td> <img src=\"pics/marija.jpg\" width=200px> </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Teachers\n",
    "\n",
    "* Barbara Plank, http://bplank.github.io\n",
    "* Rob van der Goot, http://www.robvandergoot.com\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Teaching assistants\n",
    "\n",
    "* Marija Stepanović (TA lead)\n",
    "\n",
    "* Kristian Nørgaard Jensen\n",
    "\n",
    "* Nadia Krag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Who are you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Books\n",
    "\n",
    "\n",
    "(also see references on LearnIt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Course outcomes\n",
    "\n",
    "- Discuss, clearly explain, and reflect upon central concepts, algorithms, and challenges in natural language processing (NLP) and deep learning (DL). \n",
    "- Organize, plan, and carry out collaborative work in a smaller project group. \n",
    "- Obtain, scrub, explore and preprocess a wide range of relevant raw data for a given problem. - Identify and analyze the relevant options for data collection and preprocessing and select the most suitable ones. \n",
    "- Design and implement a sound experiment in NLP \n",
    "- Distinguish and evaluate the advantages of different design choices or approaches to the same task (e.g., traditional versus deep-learning based solutions) \n",
    "- Evaluate the achieved solution and carry out a detailed error analysis, relating the findings back to the overall problem domain \n",
    "- Explain in writing (project group report) adhering to academic standards in writing \n",
    "- Succinctly present the results of the project, discuss findings and limitations \n",
    "- Reflect upon ethical considerations that arise in the deployment of language technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Part I (week 5-11): Lecture phase\n",
    "\n",
    "* Lectures:\n",
    "  * Tuesday 10:00-12:00 room 2A56 (Aud 3)\n",
    "  * Friday 10:00-12:00 room 2A56 (Aud 3)\n",
    "* Labs:\n",
    "  * Tuesday 12:00-14:00 room <b>4A14</b> + 4A20 \n",
    "  * Friday 12:00-14:00 room <b>4A20</b> + 4A22\n",
    "  * Note: boldface (lower number) room is the main room, rest for overflow\n",
    "  * Each week we release exercises which are mandatory (more information next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Group formation (week 11): Project phase starts\n",
    "\n",
    "* Group formation day and project kick-off day on March 13 \n",
    "\n",
    "### Part II (week 12-19): Project phase\n",
    "\n",
    "  * Tuesday 12:00-14:00 check in (*group needs to present an update*) \n",
    "  * Friday 12:00-14:00 work on project\n",
    "  * Continuous project work in weeks 12-19, check-ins and project work during exercise hours \n",
    "  * Required use of group-specific project github repository hosted on github.itu.dk\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Course Project: Robust Sentiment Analysis & Opinion Mining\n",
    "\n",
    "* The web is full of opinionated texts such as review text. The aim of the project is to extract sentiment and opinions from large scale web resources, addressing a fundamental challenge: \n",
    "* How to make a Sentiment analysis systems **more robust** over **text domains**?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Course Project: Robust Sentiment Analysis & Opinion Mining\n",
    "\n",
    "\n",
    "Methods involved, amongst others:\n",
    "* Data scrubbing and cleaning (processing)\n",
    "* Modeling: Comparison of traditional ML versus Neural Approaches, Error Analysis\n",
    "\n",
    "\n",
    "Computing:\n",
    "* New this year: HPC cluster (high-performance computing cluster)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Main Data Provider:\n",
    "\n",
    "<img src=\"pics/amz.png\" width=\"300px\">\n",
    "\n",
    "##### Surprise by Customer (phase 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Guest lecturers\n",
    "\n",
    "* Marija Stepanović and Andreas Søeborg Kirkedal (March 3 and 6)  *speech data*\n",
    "* Dirk Hovy (March 10) from Bocconi University on Bias and Fairness in NLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Course Materials\n",
    "* Main textbook:  [Jurafsky and Martin (*3rd* edition, draft)](https://web.stanford.edu/~jurafsky/slp3/) \n",
    "    * References to other material are given in context.\n",
    "    * This includes some recent research papers.\n",
    "    * An initial list is on LearnIt (see References)\n",
    "* Lectures and labs may contain **interactive** [jupyter](http://jupyter.org/) notes and slides\n",
    "    * View statically [here](https://github.itu.dk/bapl/2ndyearproject-2020-material/introduction.ipynb)\n",
    "    * Use interactively, see [github repo](https://github.itu.dk/bapl/2ndyearproject-2020-material) instructions  \n",
    "* This is work in progress.\n",
    "    * Use `git pull` regularly for updates\n",
    "    * *Watch* for updates\n",
    "    * Please **contribute** by adding issues/pull requests on github when you see errors\n",
    "    * Course materials are being adapted from courses I thought earlier ([2017](https://github.com/bplank/ltp-notebooks-2017), [2018](https://github.com/bplank/2018-ma-notebooks)) and course material from awesome researchers in NLP, including [Sebastian Riedel](http://www.riedelcastro.org/), [Graham Neubig](http://www.phontron.com) and others\n",
    "* For announcements, lab exercises, references etc, check [LearnIt](http://learnit.itu.dk/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Lecture Preparation\n",
    "\n",
    "* Read the provided background material\n",
    "* Do the exercises in the lab! \n",
    "* There might be quizzes in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Course Assessment and Course structure\n",
    "\n",
    "* Part I (lectures and labs): \n",
    "    * **prepares** you for the project phase\n",
    "    * Labs include exercises to help get you deeper into the material and are obligatory (they are checked but not graded) \n",
    "    * Work in week $t$ on your lab exercise of the week, TAs will check parts of your solution in week $t+1$ (randomly draw on part)\n",
    "    * No need to upload your solutions, but bring them to the next lab in week $t+1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Assessment \n",
    "\n",
    "* **Final project (100%)**, to be completed in a group of 4-5 students\n",
    "    * Released: in week 11, hand-in: **May 12, 2019** at 14:00 (learnIt) [this is a preset, fixed data, no extension!]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Late Hand-In\n",
    "\n",
    "* Late hand-ins **cannot be accepted**\n",
    "* Exceptions can be made in rare cases, e.g. due to illness with doctor's notice\n",
    "    * Get in touch with SAP at least one working day in advance see [here](https://studyguide.itu.dk/ds/your-programme/exams/illness) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Plagiarism\n",
    "\n",
    "* Don't do it\n",
    "* Don't enable it\n",
    "* Check [rules and consequences](https://student-ambassador.ku.dk/rights/avoid-plagiarism/) if unclear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Final project report and Exam\n",
    "\n",
    "* Group presentation (slides) based on **group report (final project report)** handed in on May 12 (group report has to use a scientific LaTeX paper style, more details later) and developed **code** (including data)\n",
    "* Group presentation is followed by individual exam\n",
    "* External examiner\n",
    "* Exam dates: \n",
    "    June 2,3 and 4, 2020 -- **reserve these dates in your calendar!!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Python\n",
    "\n",
    "* Lectures, lab exercises and assignments focus on **Python** (Anaconda Python version >3.6)\n",
    "* Python is a leading language for data science, machine learning etc., with many relevant libraries\n",
    "* Labs and assignments focus on the development of a mix of: standalone Python code, use of Unix command line tools and development within [jupyter notebooks](http://jupyter.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Important Dates 2020 - Summary \n",
    "\n",
    "Note: keep an eye on LearnIt for details\n",
    "\n",
    "* January 31 to March 10 Lecture Phase\n",
    "* March 13 group formation day & Project kick-off\n",
    "  * phase 1 - group presentations March 27 (Friday)\n",
    "  * phase 2 kick-off March 31 (external guest) - group presentations April 17 (Friday, external guest)\n",
    "  * phase 3 - final report due on May 12 \n",
    "* Exam (oral, incl. external censor): June 2-4, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to reach us?\n",
    "\n",
    "\n",
    "## Slack\n",
    "\n",
    "* We have a **dedicated Slack channel**: [https://2ndyearproject-2020.slack.com](https://2ndyearproject-2020.slack.com)\n",
    "* Please post questions there (instead of private emails) \n",
    "* We give low priority to **questions already answered** in previous lectures, tutorials and posts, \n",
    "    * and to **pure programming related issues**\n",
    "* We expect you to **online-search** for answers before.\n",
    "* You are highly encouraged to participate and **help each other** on the channel and during the labs. \n",
    "* The teaching team will check the discussion on slack regularly **within normal working hours**\n",
    "    * do not expect answers late in the evenings and on weekends\n",
    "    * **start working on your problem sets and project early**\n",
    "    * come to the lab sessions and ask questions there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Any questions?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to Natural Language Processing (NLP) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "After this lecture you should:\n",
    "* know what Natural Language Processing (NLP) is and why language is so challenging\n",
    "* have refreshed your memory on regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What's so special about human language?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![dogs](pics/whatwesaytodogs.png)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* most important *distinctive* human characteristics\n",
    "* the hard part in AI (intelligence)\n",
    "* *communication* was central in human development\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLP: Where are we now?\n",
    "\n",
    "*Can you think of an NLP application that you use regularly?*\n",
    "\n",
    "\n",
    "I'm sure there is at least one. ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Do you know these...?\n",
    "\n",
    "<img src=\"pics/c1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Personal assistants - Everywhere!\n",
    "<img src=\"pics/c2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Speech Recognition\n",
    "\n",
    "Speech Recognition is usually not considered core NLP. We will delve a bit into it in March."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Machine Translation\n",
    "\n",
    "![mt](pics/mt.png)\n",
    "\n",
    "http://translate.google.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Information Extraction\n",
    "![ie1](pics/ie1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Information Extraction\n",
    "![ie1](pics/ie2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "![sent](pics/sentiment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Why is it so difficult?\n",
    "\n",
    "Are these sentences ok?\n",
    "\n",
    "* The cat sat on the mat.\n",
    "* Sat the cat mat the on.\n",
    "* Mary went store.\n",
    "* Mary goed to the store.\n",
    "* The store went to Mary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is so difficult about NLP?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: *I made her duck*\n",
    "\n",
    "What is the meaning of this sentence? \n",
    "\n",
    "(Is there only one meaning?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. I cooked a duck for her\n",
    "2. I cooked a duck that belonged to her\n",
    "3. I created a (plastic?) duck she owns\n",
    "4. I caused her to quickly lower her upper body\n",
    "5. I turned her into a duck (magic!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ambiguity is everywhere\n",
    "\n",
    "* Fed <b>raises</b> interest rates 0.5% in effort to control inflation\n",
    "* Fed raises <b>interest</b> rates 0.5% in effort to control inflation\n",
    "* Fed raises interest <b>rates</b> 0.5% in effort to control inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Ambiguity** of language is manifested at many linguistic levels:\n",
    "* lexical\n",
    "* syntax\n",
    "* semantics (world knowledge)\n",
    "* pragmatics\n",
    "\n",
    "Further challenges: multilinguality, morphology ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "My one slide history of the field: \n",
    "<img src=\"pics/history.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>\"Neural Networks: A Tool for Doing Hard Things.\" (Graham Neubig)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What's a word? - Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Recap: tokenization is to identify the **words** in a string of characters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "In Python you can tokenise a text via `split`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr.',\n",
       " 'Bob',\n",
       " 'Dobolina',\n",
       " 'is',\n",
       " \"thinkin'\",\n",
       " 'of',\n",
       " 'a',\n",
       " 'master',\n",
       " 'plan.\\nWhy',\n",
       " \"doesn't\",\n",
       " 'he',\n",
       " 'quit?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Mr. Bob Dobolina is thinkin' of a master plan.\n",
    "Why doesn't he quit?\"\"\"\n",
    "text.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Why is this suboptimal? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Python allows users to construct tokenisers using \n",
    "### Regular Expressions \n",
    "\n",
    "* A\tformal\tlanguage for\tspecifying\ttext\tstrings (an algebraic notation for characterizing a set of strings)\n",
    "* Can be used to find subsets of text, or in tokenization to define **patterns** at which to split tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"pics/re1.png\">\n",
    "\n",
    "Slides from [J&M](https://web.stanford.edu/~jurafsky/slp3/slides/2_TextProc.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"pics/re2.png\">\n",
    "\n",
    "Slides from [J&M](https://web.stanford.edu/~jurafsky/slp3/slides/2_TextProc.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"pics/re3.png\">\n",
    "\n",
    "Slides from [J&M](https://web.stanford.edu/~jurafsky/slp3/slides/2_TextProc.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"pics/re4.png\">\n",
    "\n",
    "Slides from [J&M](https://web.stanford.edu/~jurafsky/slp3/slides/2_TextProc.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"pics/re5.png\">\n",
    "\n",
    "Slides from [J&M](https://web.stanford.edu/~jurafsky/slp3/slides/2_TextProc.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"pics/re6.png\">\n",
    "\n",
    "Slides from [J&M](https://web.stanford.edu/~jurafsky/slp3/slides/2_TextProc.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A **regular expression** is a compact definition of a **set** of (character) sequences.\n",
    "\n",
    "Examples:\n",
    "* `\"Mr\\.\"`: set containing only `\"Mr.\"`\n",
    "* `\" |\\n|!!!\"`: set containing the sequences `\" \"`, `\"\\n\"` and `\"!!!\"`\n",
    "* `\"[abc]\"`: set containing only the characters `a`, `b` and `c`\n",
    "* `\"\\s\"`: set of all whitespace characters\n",
    "* `\"1+\"`: set of all sequences of at least one `\"1\"` \n",
    "* etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr.',\n",
       " 'Bob',\n",
       " 'Dobolina',\n",
       " 'is',\n",
       " \"thinkin'\",\n",
       " 'of',\n",
       " 'a',\n",
       " 'master',\n",
       " 'plan.',\n",
       " 'Why',\n",
       " \"doesn't\",\n",
       " 'he',\n",
       " 'quit?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.compile('\\s').split(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Problems:\n",
    "* Bad treatment of punctuation.  \n",
    "* Easier to **define a token** than a gap. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let us use `findall` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr',\n",
       " '.',\n",
       " 'Bob',\n",
       " 'Dobolina',\n",
       " 'is',\n",
       " 'thinkin',\n",
       " 'of',\n",
       " 'a',\n",
       " 'master',\n",
       " 'plan',\n",
       " '.',\n",
       " 'Why',\n",
       " 'doesn',\n",
       " 't',\n",
       " 'he',\n",
       " 'quit',\n",
       " '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.compile('\\w+|[.?]').findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Problems:\n",
    "* \"Mr.\" is split into two tokens, should be single. \n",
    "* Lost an apostrophe. \n",
    "\n",
    "Both is fixed below ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr.',\n",
       " 'Bob',\n",
       " 'Dobolina',\n",
       " 'is',\n",
       " \"thinkin'\",\n",
       " 'of',\n",
       " 'a',\n",
       " 'master',\n",
       " 'plan',\n",
       " '.',\n",
       " 'Why',\n",
       " \"doesn't\",\n",
       " 'he',\n",
       " 'quit',\n",
       " '?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.compile('Mr.|[\\w\\']+|[.?]').findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Learning to Tokenise?\n",
    "* For English simple pattern matching often sufficient. \n",
    "* In other languages (e.g. Japanese), words are not separated by whitespace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "jap = \"今日もしないといけない。\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Try lexicon-based tokenisation ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今日', 'もし', 'と', 'けない']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.compile('もし|今日|も|しない|と|けない').findall(jap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Equally complex for certain English domains (eg. bio-medical text). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bio = \"\"\"We developed a nanocarrier system of herceptin-conjugated nanoparticles\n",
    "of d-alpha-tocopheryl-co-poly(ethylene glycol) 1000 succinate (TPGS)-cisplatin\n",
    "prodrug ...\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* d-alpha-tocopheryl-co-poly is **one** token\n",
    "* (TPGS)-cisplatin are **five**: \n",
    "  * ( \n",
    "  * TPGS \n",
    "  * ) \n",
    "  * - \n",
    "  * cisplatin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'nanocarrier',\n",
       " 'system',\n",
       " 'of',\n",
       " 'herceptin-conjugated',\n",
       " 'nanoparticles',\n",
       " 'of',\n",
       " 'd-alpha-tocopheryl-co-poly(ethylene',\n",
       " 'glycol)',\n",
       " '1000',\n",
       " 'succinate',\n",
       " '(TPGS)-cisplatin',\n",
       " 'prodrug']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.compile('\\s').split(bio)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Solution: Treat tokenisation as a **statistical NLP problem** (structured prediction). More on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "* Jurafsky & Martin, [Speech and Language Processing (Third Edition)](https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf): Chapter 2, Regular Expressions, Text Normalization, Edit Distance.\n",
    "* Manning, Raghavan & Schuetze, Introduction to Information Retrieval: [Tokenization](http://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
