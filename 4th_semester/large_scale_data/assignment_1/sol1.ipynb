{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Scale Data Analysis\n",
    "## Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Implement image classifier with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train and test set and separate labels\n",
    "train_all = np.load('fashion_train.npy')\n",
    "test_all = np.load('fashion_test.npy')\n",
    "\n",
    "train_labels = train_all[:,-1]\n",
    "train_featues = train_all[:, :-1]\n",
    "\n",
    "test_labels = test_all[:,-1]\n",
    "test_features = test_all[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn elements for preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# for validation and evaluation\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before classification I have used the combination of standard scaling and Principal Component Analysis to normalize the data to some degree and also to keep only a smaller number of features instead of the original 28 * 28 for the each picture. I have experimented with different number of components after PCA, and I have experienced an increase in performance until I have increased it to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up pipeline and process train data\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=50))\n",
    "])\n",
    "\n",
    "processed_train_data = preprocessing_pipeline.fit_transform(train_featues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have trained 4 classifiers with different parameters and have compared their accurcary score from 5-fold cross-validations. SVM with polykernel and RandomForest with 10 as max_depth seemed like the best candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.82  , 0.8135, 0.82  , 0.822 , 0.82  ])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression with cross validation\n",
    "lr_classifier = LogisticRegression(penalty='l2', tol=0.00001)\n",
    "cross_val_score(lr_classifier, processed_train_data, train_labels, cv = 5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.8375, 0.8325, 0.8395, 0.838 , 0.828 ])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier with cross validation\n",
    "rf_classifier = RandomForestClassifier(max_depth = 10)\n",
    "cross_val_score(rf_classifier, processed_train_data, train_labels, cv = 5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.762 , 0.776 , 0.7695, 0.7725, 0.766 ])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decisionTreeClassifier with cross calidation\n",
    "dc_classifier = DecisionTreeClassifier(max_depth=10)\n",
    "cross_val_score(dc_classifier, processed_train_data, train_labels, cv = 5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.8635, 0.853 , 0.867 , 0.8505, 0.8515])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM classiffier with cross validation\n",
    "sv_classifier = SVC(kernel='poly', degree = 3, coef0=2, C = 5)\n",
    "cross_val_score(sv_classifier, processed_train_data, train_labels, cv = 5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process testing data\n",
    "processed_test_data = preprocessing_pipeline.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for final evaluation I have trained the classifiers with the picked parameters on the whole training data to test their accuracy, macro precision and macro recall and confusion matrix.\n",
    "Best results were produced by SVM classifier with very high performance on dresses and trousers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "acc = 0.8122\nprecision = 0.8104489697732291\nrecall = 0.8122\n[[810   3  12  63 112]\n [  5 953  10  27   5]\n [ 23   4 811  18 144]\n [ 32  16   8 882  62]\n [170   6 165  54 605]]\n"
    }
   ],
   "source": [
    "lr_classifier.fit(processed_train_data, train_labels)\n",
    "lr_test_y = lr_classifier.predict(processed_test_data)\n",
    "print(f\"acc = {accuracy_score(test_labels, lr_test_y)}\")\n",
    "print(f\"precision = {precision_score(test_labels, lr_test_y, average= 'macro')}\")\n",
    "print(f\"recall = {recall_score(test_labels, lr_test_y, average = 'macro')}\")\n",
    "print(confusion_matrix(test_labels, lr_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "acc = 0.8448\nprecision = 0.8438225297590956\nrecall = 0.8448\n[[820   6  14  35 125]\n [  5 966   2  22   5]\n [ 32   4 847  22  95]\n [ 35   7  10 915  33]\n [157   7 123  37 676]]\n"
    }
   ],
   "source": [
    "# \n",
    "sv_classifier.fit(processed_train_data, train_labels)\n",
    "sv_test_y = sv_classifier.predict(processed_test_data)\n",
    "print(f\"acc = {accuracy_score(test_labels, sv_test_y)}\")\n",
    "print(f\"precision = {precision_score(test_labels, sv_test_y, average= 'macro')}\")\n",
    "print(f\"recall = {recall_score(test_labels, sv_test_y, average = 'macro')}\")\n",
    "print(confusion_matrix(test_labels, sv_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "acc = 0.8278\nprecision = 0.8267267677707185\nrecall = 0.8278000000000001\n[[813   1  13  67 106]\n [  3 936   8  45   8]\n [ 15   0 861  23 101]\n [ 30   9   6 913  42]\n [177   0 160  47 616]]\n"
    }
   ],
   "source": [
    "rf_classifier.fit(processed_train_data, train_labels)\n",
    "rf_test_y = rf_classifier.predict(processed_test_data)\n",
    "print(f\"acc = {accuracy_score(test_labels, rf_test_y)}\")\n",
    "print(f\"precision = {precision_score(test_labels, rf_test_y, average= 'macro')}\")\n",
    "print(f\"recall = {recall_score(test_labels, rf_test_y, average = 'macro')}\")\n",
    "print(confusion_matrix(test_labels, rf_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "acc = 0.7684\nprecision = 0.7702856724341037\nrecall = 0.7684\n[[725   5  26  67 177]\n [ 12 906  16  48  18]\n [ 31   6 756  42 165]\n [ 37  29  21 853  60]\n [164  10 159  65 602]]\n"
    }
   ],
   "source": [
    "dc_classifier.fit(processed_train_data, train_labels)\n",
    "dc_test_y = dc_classifier.predict(processed_test_data)\n",
    "print(f\"acc = {accuracy_score(test_labels, dc_test_y)}\")\n",
    "print(f\"precision = {precision_score(test_labels, dc_test_y, average= 'macro')}\")\n",
    "print(f\"recall = {recall_score(test_labels, dc_test_y, average = 'macro')}\")\n",
    "print(confusion_matrix(test_labels, dc_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Keras for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task I have implemented a simple network with two dense layers (with added dropout layers) plus a softmax at the end. I have experienced the best results with a using ReLU as activation function for both dense layers, since I have got lesser results with using hyperbolic tangent. \n",
    "To avoid overfitting I have chosen to use dropout, without it the net was likely to overfit after epoch 20. \n",
    "The reason I have not gone to a more advanced network (CNN) is that currently I am still in the process of deepening my keras knowledge and even this network outperformed the best ML classifier with 86% accuracy over 84% for poly-kernel SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing input, scaling 0-1\n",
    "train_featues_scaled = train_featues / 255.0\n",
    "test_features_scaled = test_features / 255.0\n",
    "# separate development set\n",
    "train_featues_scaled_train = train_featues_scaled[:7000, :]\n",
    "train_labels_train = train_labels[:7000]\n",
    "\n",
    "train_labels_dev = train_labels[7000:]\n",
    "train_featues_scaled_dev = train_featues_scaled[7000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(300, activation = \"relu\", input_shape = [784,]),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(100, activation = \"relu\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(5, activation = \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_12\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_36 (Dense)             (None, 300)               235500    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 300)               0         \n_________________________________________________________________\ndense_37 (Dense)             (None, 100)               30100     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense_38 (Dense)             (None, 5)                 505       \n=================================================================\nTotal params: 266,105\nTrainable params: 266,105\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = keras.optimizers.SGD(lr = 0.01), metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 7000 samples, validate on 3000 samples\nEpoch 1/30\n7000/7000 [==============================] - 1s 118us/sample - loss: 0.3377 - accuracy: 0.8776 - val_loss: 0.3869 - val_accuracy: 0.8553\nEpoch 2/30\n7000/7000 [==============================] - 1s 112us/sample - loss: 0.3320 - accuracy: 0.8731 - val_loss: 0.3870 - val_accuracy: 0.8577\nEpoch 3/30\n7000/7000 [==============================] - 1s 115us/sample - loss: 0.3324 - accuracy: 0.8766 - val_loss: 0.3917 - val_accuracy: 0.8513\nEpoch 4/30\n7000/7000 [==============================] - 1s 111us/sample - loss: 0.3285 - accuracy: 0.8757 - val_loss: 0.3980 - val_accuracy: 0.8490\nEpoch 5/30\n7000/7000 [==============================] - 1s 113us/sample - loss: 0.3190 - accuracy: 0.8826 - val_loss: 0.3888 - val_accuracy: 0.8563\nEpoch 6/30\n7000/7000 [==============================] - 1s 114us/sample - loss: 0.3152 - accuracy: 0.8823 - val_loss: 0.3998 - val_accuracy: 0.8490\nEpoch 7/30\n7000/7000 [==============================] - 1s 114us/sample - loss: 0.3142 - accuracy: 0.8834 - val_loss: 0.3895 - val_accuracy: 0.8547\nEpoch 8/30\n7000/7000 [==============================] - 1s 117us/sample - loss: 0.3100 - accuracy: 0.8854 - val_loss: 0.3838 - val_accuracy: 0.8573\nEpoch 9/30\n7000/7000 [==============================] - 1s 123us/sample - loss: 0.3042 - accuracy: 0.8887 - val_loss: 0.3761 - val_accuracy: 0.8607\nEpoch 10/30\n7000/7000 [==============================] - 1s 138us/sample - loss: 0.3032 - accuracy: 0.8847 - val_loss: 0.3965 - val_accuracy: 0.8487\nEpoch 11/30\n7000/7000 [==============================] - 1s 141us/sample - loss: 0.2994 - accuracy: 0.8899 - val_loss: 0.3758 - val_accuracy: 0.8583\nEpoch 12/30\n7000/7000 [==============================] - 1s 146us/sample - loss: 0.2940 - accuracy: 0.8904 - val_loss: 0.3720 - val_accuracy: 0.8633\nEpoch 13/30\n7000/7000 [==============================] - 1s 114us/sample - loss: 0.2891 - accuracy: 0.8909 - val_loss: 0.3759 - val_accuracy: 0.8580\nEpoch 14/30\n7000/7000 [==============================] - 1s 112us/sample - loss: 0.2881 - accuracy: 0.8944 - val_loss: 0.3737 - val_accuracy: 0.8620\nEpoch 15/30\n7000/7000 [==============================] - 1s 114us/sample - loss: 0.2890 - accuracy: 0.8906 - val_loss: 0.3722 - val_accuracy: 0.8620\nEpoch 16/30\n7000/7000 [==============================] - 1s 114us/sample - loss: 0.2832 - accuracy: 0.8937 - val_loss: 0.3727 - val_accuracy: 0.8600\nEpoch 17/30\n7000/7000 [==============================] - 1s 128us/sample - loss: 0.2797 - accuracy: 0.8951 - val_loss: 0.3962 - val_accuracy: 0.8557\nEpoch 18/30\n7000/7000 [==============================] - 1s 133us/sample - loss: 0.2768 - accuracy: 0.8969 - val_loss: 0.3862 - val_accuracy: 0.8540\nEpoch 19/30\n7000/7000 [==============================] - 1s 135us/sample - loss: 0.2756 - accuracy: 0.8971 - val_loss: 0.3819 - val_accuracy: 0.8570\nEpoch 20/30\n7000/7000 [==============================] - 1s 136us/sample - loss: 0.2737 - accuracy: 0.8971 - val_loss: 0.3677 - val_accuracy: 0.8620\nEpoch 21/30\n7000/7000 [==============================] - 1s 116us/sample - loss: 0.2691 - accuracy: 0.9001 - val_loss: 0.3639 - val_accuracy: 0.8593\nEpoch 22/30\n7000/7000 [==============================] - 1s 113us/sample - loss: 0.2610 - accuracy: 0.9053 - val_loss: 0.3715 - val_accuracy: 0.8643\nEpoch 23/30\n7000/7000 [==============================] - 1s 112us/sample - loss: 0.2587 - accuracy: 0.9047 - val_loss: 0.3741 - val_accuracy: 0.8627\nEpoch 24/30\n7000/7000 [==============================] - 1s 114us/sample - loss: 0.2558 - accuracy: 0.9036 - val_loss: 0.3694 - val_accuracy: 0.8610\nEpoch 25/30\n7000/7000 [==============================] - 1s 129us/sample - loss: 0.2549 - accuracy: 0.9066 - val_loss: 0.3739 - val_accuracy: 0.8640\nEpoch 26/30\n7000/7000 [==============================] - 1s 135us/sample - loss: 0.2502 - accuracy: 0.9086 - val_loss: 0.3650 - val_accuracy: 0.8667\nEpoch 27/30\n7000/7000 [==============================] - 1s 137us/sample - loss: 0.2503 - accuracy: 0.9077 - val_loss: 0.3629 - val_accuracy: 0.8613\nEpoch 28/30\n7000/7000 [==============================] - 1s 133us/sample - loss: 0.2446 - accuracy: 0.9141 - val_loss: 0.3779 - val_accuracy: 0.8573\nEpoch 29/30\n7000/7000 [==============================] - 1s 117us/sample - loss: 0.2383 - accuracy: 0.9149 - val_loss: 0.3665 - val_accuracy: 0.8637\nEpoch 30/30\n7000/7000 [==============================] - 1s 114us/sample - loss: 0.2418 - accuracy: 0.9130 - val_loss: 0.3665 - val_accuracy: 0.8637\n"
    }
   ],
   "source": [
    "history = model.fit(train_featues_scaled_train, train_labels_train, epochs = 30, validation_data=(train_featues_scaled_dev, train_labels_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 10000 samples\nEpoch 1/30\n10000/10000 [==============================] - 1s 87us/sample - loss: 0.2823 - accuracy: 0.8965\nEpoch 2/30\n10000/10000 [==============================] - 1s 87us/sample - loss: 0.2768 - accuracy: 0.8996\nEpoch 3/30\n10000/10000 [==============================] - 1s 87us/sample - loss: 0.2686 - accuracy: 0.9008\nEpoch 4/30\n10000/10000 [==============================] - 1s 94us/sample - loss: 0.2682 - accuracy: 0.9039\nEpoch 5/30\n10000/10000 [==============================] - 1s 95us/sample - loss: 0.2673 - accuracy: 0.9019\nEpoch 6/30\n10000/10000 [==============================] - 1s 95us/sample - loss: 0.2619 - accuracy: 0.9025\nEpoch 7/30\n10000/10000 [==============================] - 1s 93us/sample - loss: 0.2608 - accuracy: 0.9064\nEpoch 8/30\n10000/10000 [==============================] - 1s 100us/sample - loss: 0.2565 - accuracy: 0.9039\nEpoch 9/30\n10000/10000 [==============================] - 1s 96us/sample - loss: 0.2486 - accuracy: 0.9090\nEpoch 10/30\n10000/10000 [==============================] - 1s 95us/sample - loss: 0.2464 - accuracy: 0.9104\nEpoch 11/30\n10000/10000 [==============================] - 1s 98us/sample - loss: 0.2435 - accuracy: 0.9126\nEpoch 12/30\n10000/10000 [==============================] - 1s 100us/sample - loss: 0.2442 - accuracy: 0.9080\nEpoch 13/30\n10000/10000 [==============================] - 1s 94us/sample - loss: 0.2324 - accuracy: 0.9154\nEpoch 14/30\n10000/10000 [==============================] - 1s 95us/sample - loss: 0.2336 - accuracy: 0.9176\nEpoch 15/30\n10000/10000 [==============================] - 1s 89us/sample - loss: 0.2288 - accuracy: 0.9172\nEpoch 16/30\n10000/10000 [==============================] - 1s 97us/sample - loss: 0.2237 - accuracy: 0.9178\nEpoch 17/30\n10000/10000 [==============================] - 1s 99us/sample - loss: 0.2258 - accuracy: 0.9167\nEpoch 18/30\n10000/10000 [==============================] - 1s 97us/sample - loss: 0.2216 - accuracy: 0.9207\nEpoch 19/30\n10000/10000 [==============================] - 1s 93us/sample - loss: 0.2170 - accuracy: 0.9216\nEpoch 20/30\n10000/10000 [==============================] - 1s 96us/sample - loss: 0.2129 - accuracy: 0.9240\nEpoch 21/30\n10000/10000 [==============================] - 1s 91us/sample - loss: 0.2083 - accuracy: 0.9293\nEpoch 22/30\n10000/10000 [==============================] - 1s 92us/sample - loss: 0.2060 - accuracy: 0.9250\nEpoch 23/30\n10000/10000 [==============================] - 1s 100us/sample - loss: 0.2035 - accuracy: 0.9243\nEpoch 24/30\n10000/10000 [==============================] - 1s 91us/sample - loss: 0.2051 - accuracy: 0.9282\nEpoch 25/30\n10000/10000 [==============================] - 1s 95us/sample - loss: 0.1993 - accuracy: 0.9279\nEpoch 26/30\n10000/10000 [==============================] - 1s 96us/sample - loss: 0.1944 - accuracy: 0.9311\nEpoch 27/30\n10000/10000 [==============================] - 1s 101us/sample - loss: 0.1925 - accuracy: 0.9300\nEpoch 28/30\n10000/10000 [==============================] - 1s 91us/sample - loss: 0.1931 - accuracy: 0.9316\nEpoch 29/30\n10000/10000 [==============================] - 1s 106us/sample - loss: 0.1852 - accuracy: 0.9340\nEpoch 30/30\n10000/10000 [==============================] - 1s 110us/sample - loss: 0.1855 - accuracy: 0.9350\n"
    }
   ],
   "source": [
    "history = model.fit(train_featues_scaled, train_labels, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "===========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 51us/sample - loss: 0.3759 - accuracy: 0.8602\n"
    }
   ],
   "source": [
    "acc = model.evaluate(test_features_scaled, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}